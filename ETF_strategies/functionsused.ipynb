{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option('display.max_columns',999)\n",
    "pd.set_option('display.max_rows',999)\n",
    "pd.set_option('float.format','{:f}'.format)\n",
    "\n",
    "# pd.set_option('precision', 2)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "legpos = 'center left'\n",
    "size = 'medium'\n",
    "loc=(1,0.5)\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(df, x, y, figsize=(12,3), hue=None, scatter=False, cust_col='Set2', title='' ,xlabel='', ylabel='', rotation_angel=90):\n",
    "    df = df.copy()\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if (scatter):\n",
    "        ax = sns.scatterplot(x=x,y=y,data=df,palette=cust_col, ci=None)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=rotation_angel)\n",
    "        ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "        \n",
    "    elif (hue != None):\n",
    "        ax = sns.lineplot(x=x,y=y,data=df,hue=hue,palette=cust_col, ci=None)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=rotation_angel)\n",
    "        plt.legend(loc=legpos,bbox_to_anchor=loc,fontsize=size)\n",
    "        ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    else:\n",
    "        ax = sns.lineplot(x=x,y=y,data=df,palette=cust_col, ci=None)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=rotation_angel)\n",
    "        ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_stats(df,y,x):\n",
    "    X = sm.add_constant(df[x])\n",
    "    y = df[y]\n",
    "    model = sm.OLS(y,X)\n",
    "    res = model.fit()\n",
    "    stats = {'alpha_mean':res.resid.mean(), 'alpha_vol':res.resid.std(),'beta_coef':res.params[x],\n",
    "             'beta_pvalue':res.pvalues[x],'beta_tstats':res.tvalues[x],'r_square':res.rsquared}\n",
    "    return stats, res\n",
    "\n",
    "def get_rolling_regression_stats(df,y,x,window):\n",
    "    df = df.copy()\n",
    "    df = df.reset_index(drop=True)\n",
    "    cols = ['date','r_square','beta_coef','beta_tstats','beta_pvalue','alpha_mean','alpha_vol']\n",
    "    a = np.zeros(shape=(len(df),len(cols)))\n",
    "    stats = pd.DataFrame(a,columns = cols)\n",
    "    stats.date = df.date\n",
    "    \n",
    "    for idx in range(len(df)-window):\n",
    "        df_temp = df.iloc[idx:idx+window]\n",
    "        currentdate = df_temp.date.iloc[-1]\n",
    "\n",
    "        stats_temp,res = get_regression_stats(df_temp,y,x)\n",
    "        \n",
    "        for key,value in stats_temp.items():\n",
    "            stats.loc[stats.date==currentdate,key] = value\n",
    "    \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strat_rtn(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:,'rtn'] = np.where(df['r_open'] > 0, df['r_close'], -df['r_close'])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtesting_metrics(df, rtn, index):\n",
    "    df = df.copy()\n",
    "    metric = pd.DataFrame(columns=['rtn','std','Sharpe','Successrate'])\n",
    "    annualized_rtn = df[rtn].mean()*252/len(df)\n",
    "    annualized_std = df[rtn].std()*(252/len(df))**0.5\n",
    "    sharpe = annualized_rtn/annualized_std\n",
    "    successrate = 100*((df[rtn] > 0).sum()/len(df))\n",
    "    metric.loc[index,:] = [annualized_rtn, annualized_std, sharpe, successrate]\n",
    "    return metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_coverage_check(df,indiceslist,timeused=['1000','1530','close'],qualitycheckcol = ['PctMissing','FirstAvailableDate','PctMissingUpd']):\n",
    "    df = df.copy()\n",
    "    dataquality = pd.DataFrame(columns=qualitycheckcol)\n",
    "    \n",
    "    for index in indiceslist:\n",
    "        ##### select index speficic data \n",
    "        tmp = pd.DataFrame(data=df.loc[:, (timeused,index)].values, columns=timeused)\n",
    "        tmp.loc[:,'date'] = df.index\n",
    "        tmp.loc[:,'open'] = tmp.close.shift(1)\n",
    "        tmp = tmp[['date','open']+timeused]\n",
    "\n",
    "        #### select four timestamps we need which have available price \n",
    "        withoutmissing = tmp.loc[tmp[timeused].notnull().all(1)].reset_index(drop=True)\n",
    "\n",
    "        if len(withoutmissing) == 0: \n",
    "            print(index + \" don't have available price data that we need. To be excluded from our analysis.\")\n",
    "            continue\n",
    "\n",
    "        pctmissing = 100*(1-len(withoutmissing)/len(tmp)) \n",
    "        #### identify when is the first day with available data for all four timestamps we need \n",
    "        firstdate = withoutmissing.date[0]\n",
    "\n",
    "        #### slice price data after the first day with available data for all four timestamps we need \n",
    "        withoutmissingupd = tmp.loc[tmp.date >= firstdate]\n",
    "        pctmissingupd = 100*(1-withoutmissingupd.describe().loc['count',:].min()/len(withoutmissingupd))\n",
    "\n",
    "        dataquality.loc[index,:]=[round(pctmissing,2),firstdate,round(pctmissingupd,2)]\n",
    "        \n",
    "    return dataquality\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rtn_data(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:,'r_open'] = (df['1000']-df['open'])/df['open']\n",
    "    df.loc[:,'r_close'] = (df['close']-df['1530'])/df['1530']\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_outlier_analysis(df, index,timeused=['1000','1530','close']):\n",
    "    df = df.copy()\n",
    "    ##### select ETF data \n",
    "    ETF = pd.DataFrame(data=df.loc[:, (timeused,index)].values, columns=timeused)\n",
    "    ETF.loc[:,'date'] = df.index\n",
    "    ETF.loc[:,'open'] = ETF.close.shift(1)\n",
    "    ETF = ETF[['date','open']+timeused]\n",
    "    ETF = get_rtn_data(ETF)\n",
    "    return ETF\n",
    "    ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETF_backtest(df, index,col=['corr','reg_beta','reg_beta_tstats','r_squared','rtn','rtn_std','Sharpe','SuccessRate']):\n",
    "    df = df.copy()\n",
    "    \n",
    "    rst = pd.DataFrame(columns=col)\n",
    "    \n",
    "    ETF = price_outlier_analysis(df=df, index=index)\n",
    "    ETF = ETF.dropna()\n",
    "    ETF = ETF.loc[ETF.date != '2016-11-07']\n",
    "    \n",
    "    ##### regression analysis\n",
    "    corr = ETF[['r_open','r_close']].corr().loc['r_open','r_close']\n",
    "    insample_stats, insample_model = get_regression_stats(ETF,'r_close','r_open')\n",
    "    beta = insample_stats['beta_coef']\n",
    "    beta_tstats = insample_stats['beta_tstats']\n",
    "    r_square = insample_stats['r_square']\n",
    "    \n",
    "    ##### strategy analysis\n",
    "    ETF = get_strat_rtn(ETF)\n",
    "    backtest_metric = list(backtesting_metrics(ETF,'rtn',index).loc[index,:])\n",
    "    \n",
    "    rst.loc[index,:] = [corr, beta, beta_tstats, r_square]+backtest_metric\n",
    "    return rst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_variance_explained(df, index_list, component=False):\n",
    "    df = df.copy()\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(df)\n",
    "\n",
    "    n_components = len(pca.explained_variance_ratio_)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cum_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "    idx = np.arange(n_components)+1\n",
    "    df_explained_variance = pd.DataFrame([explained_variance, cum_explained_variance], \n",
    "                                         index=['variance explained', 'cumulative variance explained'], \n",
    "                                         columns=idx).T\n",
    "    \n",
    "    eigenvector = pd.DataFrame(index=index_list,data = pca.components_.T,\n",
    "                           columns=['PrincipleComponent'+str(i) for i in range(1,len(index_list)+1)]).T\n",
    "    if component:\n",
    "        return(df_explained_variance, pca.components_[0])\n",
    "    else:   \n",
    "        return (df_explained_variance, eigenvector)\n",
    "\n",
    "    \n",
    "def viz_pca_variance(df):\n",
    "    fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "    idx = np.arange(len(df))+1\n",
    "    ax1.set_title('Variance explained across principal components', fontsize=14)\n",
    "    ax1.set_xlabel('Principal Component', fontsize=12)\n",
    "    ax1.set_ylabel('Variance Explained', fontsize=12)\n",
    "    ax2 = sns.barplot(x=idx, y='variance explained', data=df_explained_variance, palette='Set2')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.grid(False)\n",
    "    ax2.set_ylabel('Cumulative variance explained', fontsize=12)\n",
    "    ax2 = sns.lineplot(x=idx, y='cumulative variance explained', data=df)\n",
    "    plt.show()\n",
    "    \n",
    "def get_rolling_PCA(df,window, index_list, col=['variance_explained','variance_explained_2']):\n",
    "    df = df.copy()\n",
    "\n",
    "    rtn = pd.DataFrame(columns = col+index_list)\n",
    "    \n",
    "    for idx in range(len(df)-window):\n",
    "        df_temp = df.iloc[idx:idx+window]\n",
    "        currentdate = df_temp.index[-1]\n",
    "        \n",
    "        variance, vector = get_pca_variance_explained(df=df_temp, index_list=index_list, component=True)\n",
    "        rtn.loc[currentdate,:] = [variance['cumulative variance explained'][1], variance['cumulative variance explained'][2]] + list(vector) \n",
    "    rtn = rtn.astype('float')\n",
    "    return rtn\n",
    "\n",
    "def get_sscore(df,x,y):\n",
    "    X = sm.add_constant(df[x])\n",
    "    y = df[y]\n",
    "    model = sm.OLS(y,X)\n",
    "    res = model.fit()\n",
    "    resid = res.resid\n",
    "    rtn = stats.zscore(resid)\n",
    "    return rtn\n",
    "\n",
    "def get_rolling_sscore(df, index_list, x='factor1'):\n",
    "    df = df.copy()\n",
    "\n",
    "    rtn = pd.DataFrame()\n",
    "    \n",
    "    for quarter in df.quarter.unique():\n",
    "        df_temp = df.loc[df.quarter==quarter]\n",
    "        for index in index_list:\n",
    "            resid = get_sscore(df=df_temp,x=x,y=index)\n",
    "            df_temp = df_temp.copy()\n",
    "            df_temp.loc[:,index] = resid\n",
    "        rtn = pd.concat([rtn,df_temp])\n",
    "    return rtn\n",
    "\n",
    "def index_tradingrtn(index, sscore, rtn, buyopen=1.25, sellopen=-1.25, buyclose=0.1,sellclose=0.1):\n",
    "    sscore = sscore.copy()\n",
    "    rtn = rtn.copy()\n",
    "    \n",
    "    priorsignal = []\n",
    "    priordate = np.nan \n",
    "    index_rtn = [] \n",
    "\n",
    "    for date in sscore.date:\n",
    "        score = sscore.loc[sscore.date == date,index].values[0]\n",
    "        if priorsignal:\n",
    "            if priorsignal[-1] == 1:\n",
    "                if abs(score) < buyclose:\n",
    "                    cumrtn = (1+ rtn.loc[(rtn.date >= priordate) & (rtn.date <= date),index]-rtn.loc[(rtn.date >= priordate) & (rtn.date <= date),'factor1']).cumprod().values[-1]-1\n",
    "                    ##### add trade rtn into ETF return list - sell position\n",
    "                    index_rtn.append(cumrtn)\n",
    "                    priorsignal.pop()\n",
    "            elif priorsignal[-1] == -1:\n",
    "                if abd(score) < sellclose:\n",
    "                    ##### add trade rtn into ETF return list - short position\n",
    "                    cumrtn = (1+ rtn.loc[(rtn.date >= priordate) & (rtn.date <= date),index]-rtn.loc[(rtn.date >= priordate) & (rtn.date <= date),'factor1']).cumprod().values[-1]-1\n",
    "                    cumrtn *= -1\n",
    "                    index_rtn.append(cumrtn)\n",
    "                    priorsignal.pop()\n",
    "        else:\n",
    "            if score >= buyopen:\n",
    "                ##### long position entry - save position and corresponding date \n",
    "                priorsignal.append(1)\n",
    "                priordate = date\n",
    "            elif score <= sellopen:\n",
    "                ##### short position entry - save position and corresponding date \n",
    "                priorsignal.append(-1)\n",
    "                priorsignal.pop()\n",
    "    return index_rtn\n",
    "\n",
    "def annualized_sharpe(rtn,days=252):\n",
    "    return round(days*(np.mean(rtn)/np.std(rtn))/len(rtn),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_scaler = StandardScaler()\n",
    "# data = std_scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
